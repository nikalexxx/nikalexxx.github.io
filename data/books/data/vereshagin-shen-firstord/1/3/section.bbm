
{def:section Схемы из функциональных элементов}
{def:index Схема из функциональных элементов}
{resource.path{/img1.png}.src{/data/books/data/vereshagin-shen-firstord/1/3/img1.png}}
{resource.path{/img2.png}.src{/data/books/data/vereshagin-shen-firstord/1/3/img2.png}}
{resource.path{/img3.png}.src{/data/books/data/vereshagin-shen-firstord/1/3/img3.png}}
{resource.path{/img4.png}.src{/data/books/data/vereshagin-shen-firstord/1/3/img4.png}}

Формулы представляют собой способ записи композиции функций.
Например, если мы сначала применяем функцию {{f}}, а потом функцию {{g}}, это можно записать формулой {{g(f(x))}}.
Но есть и другой способ: можно изобразить каждую функцию в виде прямоугольника с « входом» и « выходом» и соединить выход функции {{f}} со входом функции {{g}} (рис. {def:link scheme-1}).

{def:image.src{/img1.png}.key{scheme-1}.height{0.5}
Два способа изобразить композицию {{g\circ f}}.
}


Такое представление отнюдь не является чисто теоретическим.
Уже больше полувека электронная промышленность выпускает микросхемы, которые выполняют логические операции.
Такая микросхема имеет электрические контакты, напряжение на которых кодирует логические значения {format:b И} и {format:b Л}.
Конкретное напряжение зависит от типа схемы, но обычно это несколько вольт, и высокий потенциал (относительно заземления) считается единицей, а низкий нулём.


Одной из типичных схем является схема И-НЕ, она имеет два входа и один выход.
Сигнал на выходе является отрицанием конъюнкции сигналов на входе.
Другими словами, на выходе появляется высокий потенциал (сигнал {{1}}) тогда и только тогда, когда на одном из входов потенциал низкий ({{0}}).
Из такой схемы легко получить схему НЕ (изменяющую уровень сигнала на противоположный), соединив проводом два входа.
При этом на оба входа поступает один и тот же сигнал, и операция И его не меняет ({{p\land p=p}}), а НЕ меняет на противоположный.
Взяв два элемента И-НЕ и используя второй из них в качестве элемента НЕ, инвертирующего сигнал с выхода первого элемента, получаем схему, которая реализует функцию И.
А если поставить два элемента НЕ перед каждым из входов элемента И-НЕ, получим схему, реализующую функцию ИЛИ: {{\lnot (\lnot p\land\lnot q) \leftrightarrow (p\lor q)}}.


Теорема {def:link completeness-connectives} о полноте системы связок {def:index Теорема!о полноте системы связок ({{\land}}, {{\lor}}, {{\to}}, {{\lnot}})}
теперь гарантирует, что любую булеву функцию можно реализовать в виде схемы.
Надо иметь в виду, однако, что предлагаемая в её доказательстве конструкция (дизъюнктивная нормальная форма)
{def:index Дизъюнктивная нормальная форма}
имеет скорее теоретический интерес, поскольку приводит к схемам очень большого размера даже для простых функций (если число аргументов велико).
Например, схема, сравнивающая два {{16}}-битных числа, должна иметь {{32}} входа и поэтому в её реализации с помощью дизъюнктивной нормальной формы будет порядка {{2^{32} }}
элементов— что мало реально. (Между тем такую схему можно построить гораздо проще, из нескольких сотен элементов.)


Поэтому вопрос о том, сколько элементов нужно для реализации той или иной функции, представляет большой интерес— как практический, так и философский.
(Одна из центральных проблем математики и информатики, так называемая « проблема перебора», {def:index Проблема перебора}
может быть сформулирована в этих терминах.)


Мы сейчас дадим более формальное определение схемы и реализуемой ей булевой функции.
Но прежде всего ответим на такой вопрос— почему мы вообще говорим о схемах? Ведь можно записать композицию булевых функций в виде формулы, не будет ли это то же самое?


Оказывается, не совсем, и разницу легко увидеть на примере (рис. {def:link scheme-2}).


{def:image.src{/img2.png}.key{scheme-2}.height{0.5} Элемент входит в формулу дважды.}

Здесь один и тот же элемент схемы ({{f}}) приходится указывать в формуле дважды, поскольку его выход используется в качестве входа двух других элементов.
Схемы, в которых такого ветвления нет (на практике ветвление вполне возможно, хотя и ограничено « нагрузочной способностью выхода», как говорят инженеры), как раз и соответствуют формулам.
Но в общем случае полученная из данной схемы формула может быть длинной, даже если схема содержит небольшое число элементов, поскольку число копий может расти экспоненциально с ростом глубины схемы.


Хотя идея построения схемы из функциональных элементов, реализующих булевы функции, достаточно наглядна, дадим более формальное определение.
Фиксируем некоторый набор булевых функций {{B}}.
Пусть имеется {{n}} булевых (принимающих значения {{0}} и {{1}})
переменных {{x_1,\dots,x_n}}, называемых {em входами}.
{def:index Вход|defin}
Пусть также имеется некоторое число булевых переменных {{y_1,\dots,y_m}}, называемых {em проводниками}.
{def:index Проводник|defin}
Пусть для каждого проводника схемы задана булева функция из {{B}}, выражающая его значение через другие проводники и входы.
При этом требуется, чтобы не было циклов (цикл образуется, когда {{y_i}} зависит от {{y_j}}, которое зависит от {{y_k}}, \dots, которое зависит от {{y_i}}).
Пусть, кроме того, среди проводников выделен один, называемый {em выходом}.
{def:index Выход|defin}
В таком случае говорят, что задана {em схема из функциональных элементов в базисе {{B}}}
{def:index Схема из функциональных элементов|defin}
с {{n}} входами.
Число {{m}} называют {em размером}
{def:index Размер схемы|defin}
{def:index Схема из функциональных элементов!размер|defin}
схемы.
(С точки зрения инженера размер— это число использованных элементов, а базис {{B}}— это ассортимент доступных ему элементов.)


Отсутствие циклов гарантирует, что есть проводник, зависящий только от входов (иначе можно было бы найти цикл: возьмём какой-то проводник, затем возьмём тот проводник, от которого он зависит и т.д.).
Значение этого проводника, таким образом, однозначно определяется сигналами на входах.  Среди оставшихся проводников также нет цикла, поэтому можно найти один из них, зависящий только от уже известных, и определить его значение.
Перенумеровав проводники в таком порядке, мы можем записать последовательность присваиваний
{{
\begin{aligned}
    y_1&:= f_1(\dots);\\
    y_2&:= f_2(\dots);\\
       \dots\\
    y_m&:= f_m(\dots),\\
\end{aligned}
}}
в правых частях которых стоят функции из {{B}}, применённые ко входам и уже найденным значениям.
При этом можно считать, что результат схемы есть {{y_m}}
(как только результат получен, дальнейшие присваивания уже не нужны).
Такая программа определяет {{y_m}} при известных значениях входов, и тем самым {em вычисляет}
{def:index Булева функция!вычисляемая схемой из функциональных элементов|defin}
некоторую булеву функцию.


Теперь набор булевых функций {{B}} можно назвать {em полным}, {def:index Полный набор булевых функций|defin}
если любая булева функция может быть задана схемой из {{B}}-элементов (существует программа, её вычисляющая, при этом в правых частях присваиваний стоят функции из {{B}}).
Ясно, что это определение полноты равносильно прежнему, то есть возможности записать булеву функцию в виде формулы со связками из {{B}} (как мы говорили, разница только в том, что один и тот же элемент будет фигурировать в формуле многократно).


{em Сложностью}
{def:index Сложность!булевой функции|defin}
{def:index Булева функция!сложность|defin}
булевой функции {{f}} относительно {{B}} называют минимальный размер схемы из {{B}}-элементов, вычисляющей функцию {{f}}.
Его обозначают {{\text{size}_B(f)}}.


{#start:def:theorem.key{size-invariant}}
Пусть {{B_1}} и {{B_2}}— два полных набора булевых функций.
Тогда соответствующие меры сложности отличаются не более чем на постоянный множитель:
найдётся такое число {{C}}, что {{\text{size}_{B_1}(f)\le C\text{size}_{B_2}(f)}} и {{\text{size}_{B_2}(f)\le C\text{size}_{B_1}(f)}}
для любой функции {{f}}.
{#end:def:theorem}

{#start:def:proof}
Утверждение почти очевидно: поскольку наборы {{B_1}} и {{B_2}} полны, то каждая функция одного из наборов может быть вычислена какой-то схемой, составленной из элементов другого набора.
Теперь можно взять в качестве {{C}} наибольший размер таких схем, и неравенства будут выполняться: каждую строку программы можно заменить на {{C}} (или меньше) строк с использованием функций другого набора.
{#end:def:proof}

Что можно сказать о сложности произвольной булевой функции {{n}}
аргументов? Следующая теорема показывает, что она экспоненциально зависит от {{n}} (для «наугад взятой» функции).
{def:index Сложность!типичной булевой функции}


{#start:def:theorem.key{generic-size}}
({format:b а}) Пусть {{c>2}}.
Тогда сложность любой булевой функции {{n}} аргументов не превосходит {{c^n}} для всех достаточно больших {{n}}.

({format:b б}) Пусть {{c<2}}.
Тогда сложность большинства булевых функций {{n}} аргументов не меньше {{c^n}} для всех достаточно больших {{n}}.
{#end:def:theorem}

{#start:def:proof}
Прежде всего заметим, что по предыдущей теореме не имеет значения, какой полный базис выбрать (изменение значения {{c}} более существенно, чем умножение сложности на константу).

Первое утверждение теоремы очевидно: размер схемы, реализующей дизъюнктивную нормальную форму {def:index Дизъюнктивная нормальная форма}
с {{n}} переменными, есть {{O(n2^n)}}, поскольку имеется не более {{2^n}} конъюнктов размера {{O(n)}}. (Напомним смысл {{O}}-обозначений: {{O(n2^n)}} означает, что существует верхняя оценка вида {{Cn2^n}} для некоторой константы {{C}}.) Осталось заметить, что {{O(n2^n)<c^n}} при достаточно больших {{n}} (напомним, что {{c>2}}).

Чтобы доказать второе утверждение, оценим число различных схем (скажем, в базисе И, ИЛИ, НЕ) размера {{N}} с {{n}} аргументами.
Каждая такая схема может быть описана последовательностью из {{N}} присваиваний, выражающих одну из переменных через предыдущие.
Для каждого присваивания есть не более {{3(N+n)^2}} вариантов (три типа операций— конъюнкция, дизъюнкция, отрицание, и каждый из не более чем двух аргументов выбирается среди не более чем {{N+n}} вариантов).
Отсюда легко получить оценку {{2^{O(N\log N)} }} на число всех функций сложности не более {{N}} (считая {{N\ge n}}).

Всего булевых функций с {{n}} аргументами имеется {{2^{2^n} }}.
Из сравнения этих формул видно, что что при {{c<2}} и при достаточно больших {{n}} булевы функции сложности меньше {{c^n}} составляют меньшинство, так как {{2^{O(c^n\log c^n)} }} много меньше {{2^{2^n} }}.
{#end:def:proof}


{#start:def:problem}
Проведите вторую часть рассуждения более подробно и покажите, что при некотором {{{\varepsilon>0} }} сложность большинства булевых функций с {{n}} аргументами не меньше {{\varepsilon2^n/n}}.
{#end:def:problem}


Верхнюю оценку теоремы {def:link generic-size} можно усилить и показать, что сложность любой булевой функции {{n}} аргументов не превосходит {{O(2^n/n)}}.


{#start:def:problem}
({format:b а}) Покажите, что можно построить схему размера {{O(2^m)}} с {{2^m}} выходами, реализующую все {{2^m}} возможных конъюнктов длины {{m}} (для каждого— свой выход). (Указание:
такую схему можно построить индуктивно.)

({format:b б}) Покажите, что можно построить схему размера {{O(2^{2^m})}} с {{2^{2^m} }} выходами, реализующую все {{2^{2^m} }}
булевых функций {{m}} аргументов. (Указание: эту схему также можно построить индуктивно.)

({format:b в}) Пусть {{\varphi(x_1,\dots,x_k,y_1,\dots,y_l)}}—
булева функция, аргументы которой разбиты на две группы.
Покажите, что её можно записать в виде дизъюнкции {{2^k}} членов, каждый из которых имеет вид {{C(x_1,\dots,x_k)\land D(y_1,\dots,y_l)}}, где {{C}}— конъюнкт, а {{D}}— произвольная булева функция.
Вывести отсюда упомянутую выше оценку {{O(2^n/n)}}. (Указание: разумно положить {{k={n-\log n+c} }}, {{l={\log n-c} }}.
См. также {def:link gindikin} и {def:link cyber}.)
{#end:def:problem}


Теорема {def:link generic-size}, однако, ничего не говорит о сложности конкретных булевых функций.
Ситуация здесь такова.
Есть разнообразные методы и приёмы получения верхних оценок.
Но про нижние оценки неизвестно практически ничего.
Про многие функции мы подозреваем, что их сложность велика (экспоненциально зависит от числа входов), но доказать это пока не удаётся.
Весьма нетривиальные идеи позволяют доказывать экспоненциальные нижние оценки для некоторых специальных классов схем, например, схем из монотонных элементов или схем ограниченной глубины (использующих элементы И и ИЛИ с произвольным числом входов).
Получение экспоненциальных оценок для более общих схем— один из возможных подходов к знаменитой {em проблеме перебора}, {def:index Проблема перебора}
центральной проблеме теории сложности вычислений.


Мы не будем углубляться в эту теорию, а приведём лишь несколько верхних оценок для конкретных задач.
При этом мы не претендуем на полноту, а хотим лишь показать несколько интересных идей и приёмов.


Рассмотрим функцию сравнения {def:index Функция!сравнения}
{def:index Сложность!функции сравнения}
двух {{n}}-битовых чисел.
Она имеет {{2n}} аргументов ({{n}} для одного числа и {{n}} для другого); её значение равно {{1}}, если первое число больше второго, и {{0}} в противном случае.


Обозначим эту функцию {{\text{Comp}_n}}.
{def:index {{\text{Comp}_n}}|defin}


{#start:def:theorem.key{recursive-comparing}}
Пусть {{B}}— полный набор функций.
Существует такая константа {{C}}, что {{\text{size}_B(\text{Comp}_n)\le Cn}}.
{#end:def:theorem}

{#start:def:proof}
Заметим, что поскольку в формулировке теоремы оценка размера проводится с точностью до константы, то выбор конкретного базиса не имеет значения.
Другими словами, мы можем предполагать, что любое конечное число необходимых нам функций в этом базисе есть.


Схема сравнения чисел будет рекурсивной (чтобы сравнить два числа, мы отдельно сравниваем их левые и правые половины, а затем объединяем результаты).
При этом, как часто бывает, надо усилить утверждение, чтобы индукция прошла.
А именно, мы будем строить схему с {{2n}} входами {{x_1,\dots,x_n,y_1,\dots,y_n}} и двумя выходами, которая указывает, какой из трёх случаев {{x<y}}, {{x=y}} или {{x>y}} имеет место. (Здесь {{x,y}}— числа, записываемое в двоичной системе как {{x_1\dots x_n}} и {{y_1,\dots,y_n}}.) Два выходных бита кодируют четыре возможности, а нужно только три, так что есть некоторый запас.
Для определённости можно считать, что первый выходной бит истинен, если числа равны, а второй— если {{x<y}}.
Тогда возможны три варианта сигналов на выходе: {{10}} (равенство), {{01}}
(при {{x<y}}) и {{00}} (при {{x>y)}}.


Объясним теперь, как собрать, скажем, схему сравнения двух {{16}}-разрядных чисел.
Соберём отдельно схему сравнения старших {{8}} разрядов и младших {{8}} разрядов.
Каждая из них даст ответ в форме двух битов.
Теперь из этих четырёх битов надо собрать два. (Если в старших разрядах неравенство, то оно определяет результат сравнения; если старшие разряды равны, то результат сравнения определяется младшими разрядами.) Написанная в скобках фраза определяет булеву функцию с четырьмя битами на входе и двумя битами на выходе, и может быть реализована некоторой схемой фиксированного размера.
Таким образом, если через {{T(n)}} обозначить размер схемы, сравнивающей {{n}}-битовые числа, то получаем оценку
{{T(2n)\le 2T(n)+c}}, где {{c}}— некоторая константа, зависящая от выбора базиса.
Отсюда следует, что {{T(2^k)\le c'2^k}} при некотором {{c'}}.
В самом деле, для достаточно большого {{c'}} можно доказать по индукции, что {{T(2^k) \le c'2^k - c}}
(мы должны усилить неравенство, вычтя из правой части {{c}}, чтобы индуктивный шаг прошёл; база индукции остается верной, если {{c'}} достаточно велико).


Ту же самую оценку можно объяснить и наглядно.
Наша схема имеет вид иерархического дерева.
На каждом уровне из двух двухбитовых сигналов получается один.
Остаётся вспомнить, что в полном двоичном дереве число внутренних вершин (которое определяет размер схемы)
на единицу меньше числа листьев. (В турнире по олимпийской системе число игр на единицу меньше числа команд, так как после каждой игры одна команда выбывает.)


Все внутренние вершины и все листья (где сравниваются два бита) представляют собой схемы ограниченного размера, откуда и вытекает оценка {{T(2^k)\le c'2^k}}.


Осталось лишь сказать, что делать, если размер чисел (который мы обозначали через {{n}}) не есть точная степень двойки.
В этом случае можно увеличить размер до ближайшей сверху степени двойки (не более чем в два раза) и подать на старшие разряды входов нули.
Оба действия приводят к увеличению размера схемы не более чем в константу раз.
{#end:def:proof}


Перейдём к сложению двух {{n}}-разрядных чисел.
{def:index Сложение чисел, сложность}
(Строго говоря, тут возникает не булева функция, а функция {{\Bbb{B}^n\times\Bbb{B}^n\to\Bbb{B}^{n+1} }}, но все наши определения очевидно переносятся на этот случай.)


{#start:def:theorem.key{sequential-addition}}
Существует схема размера {{O(n)}}, осуществляющая сложение двух {{n}}-битовых чисел.
{#end:def:theorem}

{#start:def:proof}
Напомним смысл обозначения {{O(n)}}: нам надо построить схему сложения {{n}}-битовых чисел, имеющую размер не более {{Cn}} для некоторого {{C}} и для всех {{n}}.


Вспомним, как складывают числа в столбик:
{{
\begin{array}{rrrrr}
    &        0 &        1 &        1 & \\
    &        1 &        0 &        0 &1\\
    &        1 &        0 &        1 &1\\
\hline 1   &        0 &        1 &        0 &0\\
\end{array}
}}
Верхняя строка— биты переноса, нижняя— результат.
Заметим, что каждый из битов переноса или результата определяется тремя другими битами (бит результата равен сумме двух  битов слагаемых и бита переноса по модулю {{2}}, а бит переноса равен {{1}}, если хотя бы два из этих трёх битов равны {{1}}).
Поэтому можно составить схему, которая вычисляет эти биты справа налево и имеет размер {{O(n)}}.
{#end:def:proof}


Заметим, что теорему {def:link recursive-comparing} легко вывести из теоремы {def:link sequential-addition}: чтобы сравнить числа {{x}} и {{y}}, сложим число {{(2^n-1)-x}} (то есть число {{x}}, в котором все единицы заменены нулями и наоборот) и число {{y}}.
Если в старшем разряде появится единица, то {{y>x}}, а если нет, то {{y\le x}}.
Остаётся заметить, что и сложение, и обращение битов в числе {{x}}
требуют схем линейного размера.
Таким образом, сравнение чисел сводится к вычислению бита переноса.
Верно и обратное:
вычисление бита переноса сводится к сравнению двух чисел (обратим в одном из слагаемых все биты).


Тем не менее конструкция, использованная при доказательстве теоремы {def:link recursive-comparing}, имеет некоторые преимущества.
Назовём {em глубиной}
  {def:index Глубина схемы из функциональных элементов|defin}
  {def:index Схема из функциональных элементов!глубина|defin}
схемы максимальное число элементов на пути от входа к выходу.
Если представить себе, что сигнал на выходе элемента появляется не сразу после подачи сигналов на входы, а с некоторой задержкой, то глубина схемы определяет суммарную задержку.
Легко понять, что рекурсивная схема сравнения имела глубину {{O(\log n)}} (число уровней пропорционально логарифму размера входа), в то время как построенная только что схема сложения имеет глубину,   {def:index Сложение чисел, глубина}
пропорциональную {{n}} (биты переноса вычисляются последовательно, справа налево).
Но можно соединить эти два результата:


{#start:def:theorem.key{carry-save-adder}}
Существует схема сложения двух {{n}}-битовых чисел размера {{O(n)}} и глубины {{O(\log n)}}.
{#end:def:theorem}

{#start:def:proof}
Как мы видели, проблема в том, что биты переноса вычисляются последовательно, а не параллельно.
Если удастся их все вычислить схемой размера {{O(n)}} и глубины {{O(\log n)}}, дальнейшее очевидно.

Вычисление битов переноса равносильно сравнению, так что для доказательства теоремы достаточно научиться сравнивать параллельно все « суффиксы» двух {{n}}-битовых чисел {{x_1\dots x_n}} и {{y_1\dots y_n}}, —е для каждого {{i}} сравнить числа {{x_ix_{i+1}\dots x_n}} и {{y_iy_{i+1}\dots y_n}}.

Вспомним, что мы делали при сравнении чисел (скажем, длины {{8}}).
На нижнем уровне мы сравнивали биты:
{{
\begin{array}{cccccccc}
x_1 & x_2 & x_3 & x_4 & x_5 & x_6 & x_7 & x_8 \\
y_1 & y_2 & y_3 & y_4 & y_5 & y_6 & y_7 & y_8
\end{array}
}}
На следующем уровне мы сравнивали двузначные числа
{{
\begin{array}{cccc}
x_1 x_2 & x_3 x_4 & x_5 x_6 & x_7 x_8 \\
y_1 y_2 & y_3 y_4 & y_5 y_6 & y_7 y_8
\end{array}
}}
затем четырёхзначные
{{
\begin{array}{cc}
x_1  x_2   x_3  x_4 & x_5   x_6   x_7   x_8 \\
{y_1} {y_2} {y_3} {y_4} &
{y_5} {y_6} {y_7} {y_8}
\end{array}
}}
и, наконец, восьмизначные:
{{
\begin{array}{c}
x_1  x_2   x_3  x_4  x_5   x_6   x_7   x_8 \\
{y_1} {y_2} {y_3} {y_4}
{y_5} {y_6} {y_7} {y_8}
\end{array}
}}
Таким образом, для суффиксов длины {{8}}, {{4}}, {{2}} и {{1}}
результаты сравнения уже есть.
Для суффикса длины {{6}} результат можно получить, комбинируя результат сравнения {{x_3x_4 ? y_3y_4}}
и {{x_5x_6x_7x_8 ? y_5y_6y_7y_8}}.
После этого у нас есть информация о суффиксах всех чётных длин, и соединяя её с информацией с первого этапа, получаем сведения про все суффиксы.
Например, для сравнения суффиксов длины {{7}}, то есть {{x_2\dots x_8}} и {{y_2\dots y_8}}, мы соединяем результаты сравнения {{x_2}} и {{y_2}} с результатами сравнения суффиксов длины {{6}}, то есть {{x_3\dots x_8}} и {{y_3\dots y_8}}.

В общем случае картина такая: после «сужающегося дерева» мы строим «расширяющееся»; за {{k}} шагов до конца мы знаем результаты сравнения всех суффиксов, длины которых кратны {{2^k}}.
Это дерево имеет размер {{O(n)}} и глубину {{O(\log n)}}, что завершает доказательство.
{#end:def:proof}


{#start:def:problem}
Покажите, что вычитание двух {{n}}-битовых чисел по модулю {{2^n}}
выполняется схемой размера {{O(n)}} и глубины {{O(\log n)}}.
(Указание: вычитание легко сводится к сложению, если заменить нули на единицы и наоборот.)
{#end:def:problem}

Теперь займёмся умножением.
Схема умножения двух {{n}}-разрядных   {def:index Умножение чисел, сложность}
чисел имеет {{2n}} входов (по {{n}} для каждого множителя) и {{2n}}
выходов для произведения.


Посмотрим, какие оценки даёт обычный способ умножения чисел столбиком.
В нём умножение двух {{n}}-разрядных чисел сводится к сложению {{n}} копий первого числа (частично заменённых на нули в зависимости от цифр второго числа) со сдвигами.


Получение этих копий требует схемы размера {{O(n^2)}} (общее число цифр в копиях) и глубины {{O(1)}}.
Сложение двух {{2n}}-разрядных чисел мы можем выполнить с помощью схемы размера {{O(n)}} и глубины {{O(\log n)}}, так что необходимые {{n-1}} сложений можно выполнить схемой размера {{O(n^2)}} и глубины {{O(\log^2 n)}} (если складывать сначала попарно, потом результаты снова попарно и т.д.).
Оказывается, этот результат можно улучшить.
Наиболее экономные способы основаны на преобразовании Фурье (о них можно прочесть в книге {def:link aho-hopcroft-ullman}).
С их помощью, например, можно построить схему умножения {{n}}-битовых чисел, имеющую размер {{n\log^c n}}.


Эти методы далеко выходят за рамки нашего обсуждения, но два улучшения мы приведём.


{#start:def:theorem.key{fast-multiplication}}
Существует схема умножения двух {{n}}-разрядных чисел размера {{O(n^2)}} и глубины {{O(\log n)}}.
{#end:def:theorem}

{#start:def:proof}
Как мы уже говорили, умножение двух {{n}}-разрядных чисел сводится к сложению {{n}} таких чисел, и остаётся выполнить такое сложение схемой размера {{O(n^2)}} и глубины {{O(\log n)}}.
Ключевым моментом здесь является сведение сложения трёх чисел к сложению двух с помощью простой схемы размера {{O(n)}} и глубины {{O(1)}}.
В самом деле, пусть есть три числа {{x}}, {{y}} и {{z}}.
Если мы будем складывать отдельно в каждом разряде, то в разряде может накопиться любая сумма от {{0}} до {{3}}, то есть в двоичной записи от {{00}} до {{11}}.
Сформируем из младших битов этих двухбитовых сумм число {{u}}, а из старших (сдвинутых влево)— число {{v}}.
Тогда, очевидно, {{x+y+z=u+v}}.
Получение цифр числа {{u}} и {{v}} происходит параллельно во всех разрядах и требует размера {{O(n)}} и глубины {{O(1)}}.

Теперь, если надо сложить {{n}} чисел, можно разбить их на тройки и из каждых трёх чисел получить по два.
В следующий круг, таким образом, выйдут {{(2/3)n}} чисел (примерно— граничные эффекты большой роли не играют).
Их снова можно сгруппировать по тройкам и т.д. С каждым уровнем число слагаемых убывает в полтора раза, так что глубина схемы будет логарифмической.
Каждое преобразование трёх слагаемых в два требует схемы размера {{O(n)}}
и уменьшает число слагаемых на единицу, так что потребуется {{n}}
таких преобразований.
Итак, эта конструкция имеет общий размер {{O(n^2)}} и глубину {{O(\log n)}}.
Надо только отметить, что в конце у нас получается не одно число, а два, и их напоследок надо сложить— что мы умеем делать с глубиной {{O(\log n)}} и размером {{O(n)}}.
{#end:def:proof}


{#start:def:problem}
Докажите, что схема, вычисляющая булеву функцию {{f}} от {{n}}
аргументов, у которой ни один аргумент не является фиктивным, имеет размер не менее {{cn}} и глубину не менее {{c\log n}}, где {{c>0}}— некоторая константа, зависящая от выбранного набора элементов. (Аргумент функции называют {em фиктивным}, {def:index Фиктивный аргумент функции|defin}
{def:index Булева функция!фиктивный аргумент|defin}
если от него значение функции не зависит.)
{#end:def:problem}


Эта задача показывает, что если по ходу умножения двух {{n}}-разрядных чисел мы суммируем {{n}} слагаемых размера {{n}}, то оценки {{O(n^2)}} для размера и {{O(\log n)}} для глубины, полученные при доказательстве теоремы {def:link fast-multiplication}, существенно улучшить нельзя.


Однако никто не обязывает нас следовать традиционному способу умножения столбиком— отказавшись от него, мы можем уменьшить размер схемы.


{#start:def:theorem.key{recursive-multiplication}}
Существует схема умножения двух {{n}}-разрядных чисел размера {{O(n^{\log_2 3})}} и глубины {{O(\log^2 n)}}.
{#end:def:theorem}

{#start:def:proof}
Начнём с такого замечания.
Вычисляя произведение двух комплексных чисел
{{
(a+bi)(c+di)=(ac-bd)+(ad+bc)i
}}
обычным способом, мы делаем четыре умножения.
Но можно обойтись и тремя с помощью трюка: вычислить {{ac}}, {{bd}} и {{(a+b)(c+d)}}, а потом найти {{ad+bc}} как разность {{(a+b)(c+d)-ac-bd}}.

Аналогичный фокус можно проделать и для целых чисел.
Разобьём {{2n}}-битовое число на две {{n}}-битовые части, то есть представим его в виде {{a2^n+b}}.
Теперь запишем произведение двух таких чисел:
{{
(a2^n+b)(c2^n+d)=ac2^{2n}+(ad+bc)2^n+bd.
}}
Теперь видно, что достаточно найти три произведения, а именно, {{ac}}, {{bd}} и {{(a+b)(c+d)}}, чтобы определить все три слагаемых в правой части равенства.
Получается, что умножение двух {{2n}}-разрядных чисел сводится к трём умножениям {{n}}-разрядных и к нескольким сложениям и вычитаниям. (На самом деле при умножении {{(a+b)}} на {{(c+d)}}
сомножители могут быть {{(n+1)}}-разрядными, но это не страшно, так как обработка лишнего разряда сводится к нескольким сложениям.)

Для размера схемы это даёт рекурсивную оценку
{{
S(2n)\le 3S(n)+O(n)
}}
, из которой следует, что {{S(n)=O(n^{\log_2 3})}}.
В самом деле, для умножения {{n}}-разрядных чисел требуется дерево рекурсивных вызовов глубины {{\log_2 n}} и степени ветвления {{3}}.
Заметим, что размер схемы в вершине пропорционален числу складываемых битов.
При переходе от одного уровня к следующему (более близкому к корню) размер слагаемых растёт вдвое, а число вершин уменьшается втрое, поэтому общее число элементов на этом уровне уменьшается в полтора раза.
Таким образом, при движении по уровням от листьев к корню получается убывающая геометрическая прогрессия со знаменателем {{2/3}}, сумма которой всего лишь втрое превосходит её первый член.
Остаётся заметить, что число листьев равно {{3^{\log_2 n}=n^{\log_2 3} }}.

Оценка глубины также очевидна: на каждом уровне мы имеем схему сложения глубины {{O(\log n)}}, а число уровней есть {{O(\log n)}}.
{#end:def:proof}


На этом мы завершаем знакомство со схемами из функциональных элементов, выполняющими арифметические операции.
О них можно прочесть в главе 29 учебника Кормена, {def:glossary Кормен}
Лейзерсона {def:glossary Лейзерсон}
и Ривеста {def:link cormen-leiserson-rivest}
{def:glossary Ривест}
и в книге Ахо, {def:glossary Ахо}
Хопкрофта {def:glossary Хопкрофт}
и Ульмана {def:link aho-hopcroft-ullman}.
{def:glossary Ульман}


Рассмотрим теперь функцию «голосования» {def:index Функция!голосования|defin}
{def:index majority} (majority).
{def:index Сложность!функции голосования}
Она имеет нечётное число аргументов, и значение её равно {{0}} или {{1}} в зависимости от того, какое из двух значений чаще встречается среди входов.


{#start:def:theorem}
Для функции голосования существует схема размера {{O(n)}} и глубины {{O(\log n\log\log n)}}.
{#end:def:theorem}

{#start:def:proof}
На самом деле можно даже вычислить общее число единиц среди входов.
Это делается рекурсивно: считаем отдельно для каждой половины, потом складываем.
Получается логарифмическое число уровней.
На верхнем уровне надо складывать числа размера {{\log n}}, на следующем— размера {{{(\log n -1)} }} и так до самого низа, где складываются однобитовые числа (то есть биты входа).
Какой средний размер складываемых чисел? Половина вершин в дереве приходится на нижний уровень (числа длины {{1}}), четверть— на следующий (числа длины {{2}}) и т.д. Вспоминая, что ряд {{\sum (k/2^k)}} сходится, видим, что средний размер складываемых чисел есть {{O(1)}} и общий размер схемы есть {{O(n)}}.
А общая глубина есть {{O(\log n \log\log n)}}, так как на каждом из {{\log n}}
уровней стоит схема глубины {{O(\log\log n)}}.
{#end:def:proof}


Заметим, что хотя функция голосования монотонна, построенная схема её вычисления содержит немонотонные элементы (поскольку операция сложения не монотонна).
Мы уже говорили, что всякую монотонную функцию можно составить из конъюнкций и дизъюнкций.
Для функции голосования есть очевидный способ это сделать: написать дизъюнкцию всех конъюнкций размера {{(n+1)/2}} (напомним, что число входов {{n}} предполагается нечётным).
Однако при этом получится схема экспоненциального по {{n}} размера.


{#start:def:theorem}
Существует схема размера {{O(n^c)}} и глубины {{O(\log n)}}, составленная только из элементов И и ИЛИ (с двумя входами), вычисляющая функцию голосования.
{#end:def:theorem}

{#start:def:proof}
Для начала заметим, что ограничение на размер является следствием ограничения на глубину, так как элементы И и ИЛИ имеют только два входа и число элементов в схеме глубины {{d}} есть {{O(2^d)}}.

Схема будет строиться из элементов большинства с тремя входами.
(Каждый из них можно собрать из конъюнкций и дизъюнкций по формуле {{(a\land b)\lor (a\land c)\lor (b\land c)}}.)
Выход схемы будет большинством из трёх значений, каждое из которых есть большинство из трёх значений и т.д. (рис. {def:link majority-scheme}).

{def:image.src{/img3.png}.key{majority-scheme}.height{0.5}
Дерево из элементов {{3}}-большинства.
}

Продолжая эту конструкцию на {{k}} уровнях, мы получим схему с {{3^k}} входами. (Отметим, что эта схема не будет вычислять большинство среди своих входов— по той же причине, по которой результат непрямого голосования может отличаться от мнения большинства.) Но мы сделаем вот какую странную вещь: возьмём {{k}}
равным {{c\log n}} при достаточно большом коэффициенте пропорциональности {{c}} (число входов такой схемы будет полиномиально зависеть от {{n}}) и напишем на входах случайно выбранные переменные из данного нам набора {{x_1,\dots,x_n}}.
(Переменные, записываемые на разных входах, выбираются независимо.) Оказывается, что с ненулевой вероятностью эта схема будет вычислять функцию большинства среди {{x_1,\dots,x_n}}, если константа {{c}}
достаточно велика.
Следовательно, искомая схема существует.


Обратите внимание: нам удастся доказать существование интересующей нас схемы, не предъявив её явно. (Такое использование вероятностных методов в комбинаторных рассуждениях часто бывает полезно.)


Итак, почему же схема с положительной вероятностью вычисляет функцию большинства? Это доказывается так: рассмотрим какой-то один набор значений на входах и докажем, что на этом конкретном наборе случайная схема выдаёт правильный ответ с вероятностью, очень близкой к единице (равной {{1-\varepsilon}} при очень малом {{\varepsilon}}).


Если число {{\varepsilon}} настолько мало, что остаётся меньшим единицы даже после умножения на число возможных входов ({{2^n}}), то получаем требуемое (каждое из {{2^n}} событий имеет вероятность не меньше {{1-\varepsilon}}, значит их пересечение имеет вероятность не меньше {{1-2^n\varepsilon>0}}).


Итак, осталось оценить вероятность того, что случайная схема даст правильный ответ на данном входе.
Пусть доля единиц среди всех входов равна {{p}}.
Тогда на каждый входной провод схемы подаётся единица с вероятностью {{p}} и нуль с вероятностью {{1-p}}
(выбор случайной переменной даёт единицу с вероятностью {{p}}), причём сигналы на всех входах независимы.


Если на трёх входах элемента {{3}}-большинства сигналы независимы, и вероятность появления единицы на каждом входе есть {{p}}, то вероятность появления единицы на выходе есть {{\varphi(p)=3p^2(1-p)+p^3=3p^2-2p^3}}.
На следующих уровнях вероятность появления единицы будет равна {{\varphi(\varphi(p)),\varphi(\varphi(\varphi(p))),\dots}} График функции {{\varphi(x)}} на отрезке {{[0,1]}}
(рис. {def:link iterations-majority}) показывает, что при итерациях функции {{\varphi}} дисбаланс (отклонение от середины) нарастает и последовательность стремится к краю отрезка.
Надо только оценить число шагов.

{def:image.src{/img4.png}.key{iterations-majority}.height{0.5}
Итерируемая функция {{\varphi}}.
}

Если вначале единицы составляют большинство из {{n}} аргументов (напомним, {{n}} нечётно), то их как минимум {{(n+1)/2}}, так что {{p\ge (n+1)/2n=1/2+1/(2n)}}.
Таким образом, начальный дисбаланс составляет как минимум {{1/2n}}.
А в конце нам нужно приблизиться к краю отрезка на расстояние {{2^{-n} }}.


Итак, нам осталось доказать такую лемму (относящуюся скорее к математическому анализу):


{format:pre Лемма}.
Пусть последовательность {{x_k\in[0,1]}} задана рекуррентной формулой {{x_{k+1}=\varphi(x_k)}}, где
{{
\varphi(x)=3x^2-2x^3.
}}
Пусть {{x_0\ge1/2+1/(2n)}}.
Тогда последовательность {{x_k}} монотонно возрастает и приближается к {{1}} на расстояние {{2^{-n} }} за {{O(\log n)}} шагов. [Симметричное утверждение верно и при {{x_0\le 1/2-1/(2n)}}.]

Идея доказательства: посмотрим на функцию вблизи точки {{1/2}} и у краёв отрезка.
В точке {{1/2}} производная больше {{1}}, поэтому удаление от {{1/2}} растёт как геометрическая прогрессия, и точка перейдёт какую-то фиксированную границу (например, {{0{,}51}}) не позднее чем за {{O(\log n)}} шагов.
Затем потребуется {{O(1)}} шагов, чтобы дойти, скажем, до {{0{,}99}}.
В единице первая производная функции равна нулю, поэтому расстояние до единицы каждый раз примерно возводится в квадрат, и потому для достижения погрешности {{2^{-n} }} потребуется {{O(\log n)}} шагов (как в методе Ньютона отыскания корня).
Всего получается {{O(\log n)+O(1)+O(\log n)}} шагов, что и требовалось.
{#end:def:proof}


На самом деле справедливо гораздо более сильное утверждение:
существует схема размера {{O(n\log n)}} и глубины {{O(\log n)}}, состоящая только из элементов И и ИЛИ, которая имеет {{n}} входов и {{n}} выходов и осуществляет сортировку последовательности {{n}} нулей и единиц (это означает, что на выходе столько же единиц, сколько на входе, причём выходная последовательность всегда невозрастающая).
Ясно, что средний бит выхода в такой ситуации реализует функцию большинства.


При кажущейся простоте формулировки единственная известная конструкция такой схемы (сортирующая сеть AKS, придуманная Айтаи, {def:glossary Айтаи}
Комлошом {def:glossary Комлош}
и Сцемереди {def:glossary Сцемереди}
в 1983 году)
весьма сложна, и появление какой-то более простой конструкции (с логарифмической глубиной!) было бы замечательным достижением.
Но разрешив большую глубину, мы сильно упрощаем задачу: для глубины {{O(\log^2 n)}} уже есть несколько сравнительно простых конструкций, а для глубины {{O(n)}} годится совсем простая сеть.


{#start:def:problem}
Постройте сортирующую сеть глубины {{O(n)}} с {{O(n^2)}} элементов И и ИЛИ.  (Указание.
Два элемента И и ИЛИ вместе образуют сортирующую сеть для двух входов.
Вспомнив сортировку пузырьком, придумайте, как из таких сетей собрать искомую, на каждом шаге группируя переменные в пары.
Обратите внимание, что доказательство оценки на глубину не вполне тривиально.)
{#end:def:problem}


Многие нетривиальные результаты теории алгоритмов можно переформулировать в терминах сложности каких-то булевых функций.
Например, есть вероятностный алгоритм проверки простоты {def:index Алгоритм проверки простоты}
большого числа (применяемый в системах шифрования для проверки простоты чисел из нескольких тысяч цифр).
Используя этот алгоритм, можно доказать такой факт: существует схема проверки простоты {{n}}-битового числа (на вход подаются {{n}}
цифр, на выходе появляется единица, если число простое, и нуль, если число составное), размер которой ограничен полиномом от {{n}}.


Вернёмся к общим утверждениям о схемах и формулах.
Мы уже говорили, что с точки зрения измерения размера схемы и формулы—
это разные вещи (схемы экономичнее, так как в них одинаковые подформулы учитываются только один раз).
Оказывается, что размер формулы можно связать с глубиной схемы.
{def:index Глубина схемы из функциональных элементов}
{def:index Схема из функциональных элементов!глубина}


Будем называть {em размером}
{def:index Размер формулы|defin}
формулы число логических связок в ней.
Мы предполагаем, что формула использует конъюнкции, дизъюнкции и отрицания, и в схемах будем использовать такие же элементы.
Напомним, что размером схемы {def:index Размер схемы}
{def:index Схема из функциональных элементов!размер}
мы называли число элементов, а сложностью {def:index Сложность!булевой функции}
{def:index Булева функция!сложность}
булевой функции— минимальный размер схемы, её вычисляющей.
Сложность функции {{h}} обозначалась {{\text{size}(h)}} (точнее {{\text{size}_B(h)}}, где {{B}}— набор разрешённых функциональных элементов, но сейчас мы договорились использовать конъюнкции, дизъюнкции и отрицания и опускаем индекс {{B}}).


Минимальный размер формулы, выражающей функцию {{h}}, будем обозначать {{\text{fsize}(h)}}.
Очевидно, {{\text{size}(h)\le\text{fsize}(h)}}.
Более интересно, однако, следующее утверждение, связывающее размер схемы с глубиной формулы.
Обозначим через {{\text{depth}(h)}}
минимальную глубину схемы, вычисляющей функцию {{h}}.


{#start:def:theorem.key{formula-size-depth}}
Имеют место оценки {{
\text{fsize}(h)\le c_1^{\text{depth}(h)} \quad\text{и}\quad \text{depth}(h)\le c_2\log\text{fsize}(h)
}} (для некоторых констант {{c_1}} и {{c_2}} и для всех {{h}}).
Другими словами, {{\text{depth} }} и {{\log\text{fsize} }} отличаются не более чем в константу раз.
{#end:def:theorem}

{#start:def:proof}
Первая оценка очевидна: если мы скопируем повторяющиеся фрагменты схемы, чтобы развернуть её в дерево, то глубина не изменится.
Если она равна {{k}}, то в полученном дереве будет не больше {{2^k-1}} элементов и соответствующая формула имеет размер не более {{{2^k-1} }}. (Напомним, что элементами являются конъюнкции, дизъюнкции и отрицания, и потому ветвление не больше {{2}}.)


То же самое можно сказать индуктивно.
Пусть глубина схемы равна {{k}}.
Выход схемы является выходом некоторого элемента.
Тогда на его входы подаются булевы функции глубины не больше {{k-1}}.
По предположению индукции их можно записать формулами размера {{2^{k-1}-1}}.
Таких формул максимум две, так что общий размер не превосходит {{2(2^{k-1}-1)+1=2^k-1}}.


Вторая оценка сложнее.
Если мы будем преобразовывать формулу в схему естественным образом (введя вспомогательную переменную для каждой подформулы), то глубина получившейся схемы может быть близка к размеру формулы, а не к его логарифму.
Например, если формула имеет вид {{(\ldots((p_1\land p_2)\land p_3)\land\dots p_n)}}, то у нас получится цепочка элементов И, у которых каждый следующий подвешен к левому входу предыдущего, и глубина равна {{{n-1} }}.
Конечно, если использовать ассоциативность конъюнкции, скобки можно переставить и получить более сбалансированное дерево глубины примерно {{\log n}}, как и требуется.
Но как выполнить такое преобразование в случае произвольной формулы?


Обозначим данную нам формулу через {{F}}.
Выберем у неё некоторую подформулу {{G}} (как именно, мы объясним позже).
Рассмотрим формулу {{F_0}}, которая получится, если вместо {{G}} подставить {{0}}
(ложь), а также формулу {{F_1}}, которая получится, если подставить {{1}}.
Легко понять, что {{F}} равносильна формуле {{((F_0 \land\lnot G)\lor (F_1\land G))}}.
Если теперь удастся заменить формулы {{F_0, F_1, G}} схемами глубины не больше {{k}}, то для {{F}} получится схема глубины не больше {{k+3}}.


Такое преобразование полезно, если все три формулы {{F_1, F_0, G}}
имеют заметно меньший размер, чем исходная формула {{F}}.


{format:pre Лемма}.
У любой формулы достаточно большого размера {{n}}
есть подформула размера от {{n/4}} до {{3n/4}}.


Доказательство.
Каждая формула есть конъюнкция двух подформул, дизъюнкция двух подформул или отрицание подформулы.
Начав со всей формулы, будем переходить к её подформулам, на каждом шаге выбирая из двух подформул наибольшую.
Тогда на каждом шаге размер убывает не более чем в два раза, и потому мы не можем миновать промежуток {{[n/4, 3n/4]}}, концы которого отличаются втрое. (На самом деле тут есть небольшая неточность: размер формулы может убывать чуть быстрее, чем вдвое, так как размер формулы на единицу больше суммы размеров частей, но у нас есть запас, поскольку концы промежутка отличаются втрое, а не вдвое.) Лемма доказана.


Выбирая подформулу {{G}} с помощью этой леммы, мы гарантируем, что размер всех трёх формул {{F_0,F_1,G}} не превосходит {{3/4}}
размера исходной формулы (подстановка нуля или единицы может только уменьшить размер формулы— некоторые части можно будет выбросить).


Применим ко всем трём формулам {{F_0}}, {{F_1}} и {{G}} тот же приём, выделим в них подформулы среднего размера и так далее, пока мы не спустимся до формул малого размера, которые можно записать в виде схем как угодно.
В итоге получится дерево с логарифмическим числом уровней, на каждом из которых стоят схемы глубины {{3}}, а в листьях находятся схемы глубины {{O(1)}}.


Другими словами, индукцией по длине формулы, выражающей функцию {{h}}, мы доказываем, что {{\text{depth}(h)=O(\log\text{fsize}(h))}}.
{#end:def:proof}


{#start:def:problem}
Определим глубину формулы как максимальное число вложенных пар скобок; для единообразия будем окружать отрицание скобками и писать {{(\lnot A)}} вместо {{\lnot A}}.
Покажите, что при этом не получится ничего нового: минимальная глубина формулы, записывающей некоторую функцию {{f}}, совпадает с минимальной глубиной схемы, вычисляющей {{f}}.
{#end:def:problem}


Определение формульной сложности {{\text{fsize}(h)}} зависит от выбора базиса.
Оказывается, что здесь (в отличие от схемной сложности) выбор базиса может изменить {{\text{fsize}(h)}} более чем в константу раз.


{#start:def:problem}
Объясните, почему доказательство теоремы {def:link size-invariant}
не переносится на случай формул.
{#end:def:problem}


Так происходит с функцией {{{p_1\oplus p_2\oplus\ldots\oplus p_n} }} (знак {{\oplus}} обозначает сложение по
{def:index Сложение по модулю {{2}}}
модулю {{2}}).
Эта функция имеет формульную сложность {{O(n)}}, если сложение по модулю {{2}} входит в базис.
Однако в базисе И, ИЛИ, НЕ она имеет большую сложность, как доказала Б.А.Субботовская.
{def:glossary Субботовская}
Идея доказательства такова: если заменить случайно выбранную переменную в формуле с конъюнкциями и дизъюнкциями на случайно выбранное значение {{0}} или {{1}}, то формула упростится (не только эта переменная пропадёт, но с некоторой вероятностью пропадут и другие).
Если делать так многократно, то от формулы останется небольшая часть— с другой стороны, эта часть всё равно должна реализовывать сложение оставшихся аргументов по модулю {{2}}.


{#start:def:problem}
Докажите, что функция большинства может быть вычислена не только схемой, но и формулой полиномиального размера, содержащей только связки И и ИЛИ.
{#end:def:problem}


{#start:def:problem}
Докажите, что {{\text{fsize}_1(h)}} и {{\text{fsize}_2(h)}} для одной булевой функции {{h}} и двух полных базисов полиномиально связаны: существует полином {{P}} (зависящий от выбора базисов), для которого {{\text{fsize}_2 (h) \le P(\text{fsize}_1(h))}} при всех {{h}}.
(Указание: использовать теорему {def:link formula-size-depth}.)
{#end:def:problem}
